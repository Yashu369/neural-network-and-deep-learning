import pandas as pd
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
import numpy as np

df = pd.read_csv("spam dataset.csv")
texts = df["text"].values
labels = df["label"].apply(lambda x: 1 if x.lower() == 'spam' else 0).values


tokenizer = Tokenizer(num_words=500)
tokenizer.fit_on_texts(texts)

seqs = tokenizer.texts_to_sequences(texts)
max_len = 20
padded = pad_sequences(seqs, maxlen=max_len, padding="post")

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=500 + 1,
                              output_dim=16,
                              input_length=max_len),
    tf.keras.layers.GlobalAveragePooling1D(),
    tf.keras.layers.Dense(16, activation="relu"),
    tf.keras.layers.Dense(1, activation="sigmoid")
])

model.compile(loss="binary_crossentropy",
              optimizer="adam",
              metrics=["accuracy"])

model.fit(padded, labels.astype("float32"),
          epochs=10, batch_size=32, verbose=1)


test_email = ["Get free stuff now!"]
test_seq = tokenizer.texts_to_sequences(test_email)
test_padded = pad_sequences(test_seq, maxlen=max_len, padding="post")

pred = model.predict(test_padded)
result = "Spam\n" if pred[0, 0] > 0.5 else "Not Spam\n"
print(f"{result}Probability: {pred[0, 0]:.4f}")
